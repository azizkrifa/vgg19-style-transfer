{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d20e2d1",
   "metadata": {},
   "source": [
    "## üß† Introduction to Neural Style Transfer\n",
    "\n",
    "Neural Style Transfer is a computer vision technique that allows us to combine the **content of one image** with the **style of another** to produce a new, artistic image.\n",
    "\n",
    "In this project, we use the **VGG19** convolutional neural network pre-trained on ImageNet to extract:\n",
    "\n",
    "- **Content features** (structure and layout) from a **content image**\n",
    "- **Style features** (color, texture, and brushstrokes) from a **style image**\n",
    "\n",
    "Then, we optimize a new image to minimize a **loss function** that balances:\n",
    "\n",
    "- **Content loss**: how different the generated image is from the content image\n",
    "- **Style loss**: how different the textures and colors are from the style image\n",
    "\n",
    "This notebook implements the entire process step-by-step, using **TensorFlow** and **Keras**.\n",
    "\n",
    "---\n",
    "\n",
    "### üìù Steps Overview:\n",
    "\n",
    "1. Load and preprocess content & style images\n",
    "2. Extract feature maps from VGG19 layers\n",
    "3. Compute Gram matrices for style\n",
    "4. Define loss functions\n",
    "5. Optimize an image starting from the content image\n",
    "6. Visualize stylized results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39be3401",
   "metadata": {},
   "source": [
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8a10f8",
   "metadata": {},
   "source": [
    "## üì¶ Step 1: Import Dependencies\n",
    "\n",
    "We begin by importing essential Python libraries:\n",
    "\n",
    "- **TensorFlow**: For deep learning and model operations (VGG19)\n",
    "- **NumPy**: For numerical operations on image tensors\n",
    "- **Matplotlib**: To visualize images during training\n",
    "- **PIL (Python Imaging Library)**: To load and manipulate images\n",
    "- **Warnings/OS**: To suppress unnecessary logs and keep the notebook clean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f752fb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì¶ Import Required Libraries\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# Suppress TensorFlow and Python warnings for cleaner output\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # Suppress TF messages: 0=all, 1=ignore INFO, 2=ignore WARNING, 3=ignore ERROR\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c234e4",
   "metadata": {},
   "source": [
    "\n",
    "-----\n",
    "\n",
    "## üñºÔ∏è Step 2: Load and Preprocess Images\n",
    "\n",
    "We define a utility function `load_image()` that:\n",
    "\n",
    "- Opens the image using **PIL**\n",
    "- Converts it to **RGB**\n",
    "- Resizes it to a maximum dimension (default: 300px) while maintaining the aspect ratio\n",
    "- Normalizes the pixel values to the [0, 1] range\n",
    "- Adds a batch dimension so it can be fed into the VGG19 model\n",
    "\n",
    "This ensures both the content and style images are in the correct format for processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4d7c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path_to_img, max_dim=300):\n",
    "    img = Image.open(path_to_img)                  # Open the image file\n",
    "    img = img.convert('RGB')                       # Ensure it's in RGB format\n",
    "    img.thumbnail((max_dim, max_dim))              # Resize while preserving aspect ratio\n",
    "    img = np.array(img)                            # Convert to NumPy array\n",
    "    img = img[tf.newaxis, ...] / 255.0             # Add batch dimension & normalize [0,1]\n",
    "    return tf.convert_to_tensor(img, dtype=tf.float32)  # Convert to TensorFlow tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484955ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_image = load_image(\"content.jpg\")\n",
    "style_image = load_image(\"style.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6465cdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained VGG19 without the fully connected layers (for feature extraction)\n",
    "vgg = tf.keras.applications.VGG19(include_top=False, weights='imagenet') \n",
    "\n",
    "vgg.trainable = False  # Freeze the model weights; do not update during training"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
